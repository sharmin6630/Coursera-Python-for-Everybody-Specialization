{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Programs that Surf the Web.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOuFu19qgNajIZA2r+1CnBM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharmin6630/Python-for-Everybody/blob/master/Using%20Python%20to%20Access%20Web%20Data/Programs_that_Surf_the_Web.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtII3tzhFNp9",
        "colab_type": "text"
      },
      "source": [
        "# **Programs that Surf the Web**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4mHhLAoFw0p",
        "colab_type": "code",
        "outputId": "de326959-fdec-4410-a803-eca0c651b5c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import urllib.request, urllib.parse, urllib.error\n",
        "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
        "for line in fhand :\n",
        "  print(line.decode().strip())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "But soft what light through yonder window breaks\n",
            "It is the east and Juliet is the sun\n",
            "Arise fair sun and kill the envious moon\n",
            "Who is already sick and pale with grief\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VV0zBenQUhJ",
        "colab_type": "code",
        "outputId": "5a30909f-8cee-4353-ad38-62820f25c34e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "fhand = urllib.request.urlopen('http://data.pr4e.org/page1.htm')\n",
        "for line in fhand :\n",
        "  print(line.decode().strip())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<h1>The First Page</h1>\n",
            "<p>\n",
            "If you like, you can switch to the\n",
            "<a href=\"http://data.pr4e.org/page2.htm\">\n",
            "Second Page</a>.\n",
            "</p>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gSzcmWqRX14",
        "colab_type": "code",
        "outputId": "bf036b5e-c3bc-493f-a5ac-ab627338ab41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import urllib.request, urllib.parse, urllib.error\n",
        "import bs4\n",
        "from bs4 import BeautifulSoup\n",
        "url = input(\"Enter the url: \")\n",
        "html = urllib.request.urlopen(url).read()\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "#Retrieve all of the anchor tag\n",
        "tags = soup('a')\n",
        "for tag in tags :\n",
        "  print(tag.get('href', None))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the url: http://data.pr4e.org/page2.htm\n",
            "page1.htm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c54ciBO3FOtx",
        "colab_type": "text"
      },
      "source": [
        "# **Assignment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSgphTPHFxrI",
        "colab_type": "text"
      },
      "source": [
        "**Scraping Numbers from HTML using BeautifulSoup**\n",
        "\n",
        "```\n",
        "Scraping Numbers from HTML using BeautifulSoup In this assignment you will \n",
        "write a Python program similar to http://www.py4e.com/code3/urllink2.py. The\n",
        "program will use urllib to read the HTML from the data files below, and parse\n",
        "the data, extracting numbers and compute the sum of the numbers in the file.\n",
        "We provide two files for this assignment. One is a sample file where we give \n",
        "you the sum for your testing and the other is the actual data you need to \n",
        "process for the assignment.\n",
        "\n",
        "Sample data: http://py4e-data.dr-chuck.net/comments_42.html (Sum=2553)\n",
        "Actual data: http://py4e-data.dr-chuck.net/comments_558234.html (Sum ends with \n",
        "87)\n",
        "You do not need to save these files to your folder since your program will read\n",
        "the data directly from the URL.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EJc1GmrFy10",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fde92941-0c98-44df-8d35-5f8347948547"
      },
      "source": [
        "import urllib.request, urllib.parse, urllib.error\n",
        "import bs4\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "sum_val = 0\n",
        "cnt = 0\n",
        "url = input(\"Enter the url: \")\n",
        "html = urllib.request.urlopen(url).read()\n",
        "soup = BeautifulSoup(html)\n",
        "#Retrieve all of the anchor tag\n",
        "data = soup('span')\n",
        "for line in data :\n",
        "  num = line.getText()\n",
        "  sum_val += int(num)\n",
        "  cnt += 1\n",
        "\n",
        "print(\"Count\", cnt)\n",
        "print(\"Sum\", sum_val)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the url: http://py4e-data.dr-chuck.net/comments_558234.html\n",
            "Count 50\n",
            "Sum 2687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jcj4YhAImtWo",
        "colab_type": "text"
      },
      "source": [
        "**Following Links in Python**\n",
        "\n",
        "```\n",
        "In this assignment you will write a Python program that expands on http://www.\n",
        "py4e.com/code3/urllinks.py. The program will use urllib to read the HTML from \n",
        "the data files below, extract the href= vaues from the anchor tags, scan for a \n",
        "tag that is in a particular position relative to the first name in the list, \n",
        "follow that link and repeat the process a number of times and report the last \n",
        "name you find.\n",
        "\n",
        "We provide two files for this assignment. One is a sample file where we give \n",
        "you the name for your testing and the other is the actual data you need to \n",
        "process for the assignment\n",
        "\n",
        "Sample problem: Start at http://py4e-data.dr-chuck.net/known_by_Fikret.html\n",
        "Find the link at position 3 (the first name is 1). Follow that link. Repeat \n",
        "this process 4 times. The answer is the last name that you retrieve.\n",
        "Sequence of names: Fikret Montgomery Mhairade Butchi Anayah\n",
        "Last name in sequence: Anayah\n",
        "Actual problem: Start at: http://py4e-data.dr-chuck.net/known_by_Kelsey.html\n",
        "\n",
        "Find the link at position 18 (the first name is 1). Follow that link. Repeat \n",
        "this process 7 times. The answer is the last name that you retrieve.\n",
        "Hint: The first character of the name of the last page that you will load is: C\n",
        "Strategy\n",
        "The web pages tweak the height between the links and hide the page after a few seconds \n",
        "to make it difficult for you to do the assignment without writing a Python program. \n",
        "But frankly with a little effort and patience you can overcome these attempts to make it \n",
        "a little harder to complete the assignment without writing a Python program. \n",
        "\n",
        "But that is not the point. The point is to write a clever Python program to solve the program.\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlOc_8xDmszL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b1050a05-c4a9-4fef-a13c-95e06fb63369"
      },
      "source": [
        "import requests\n",
        "import bs4\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "def name_ret(cnt, url, pos, cur_name) :\n",
        "  if cnt == 0 :\n",
        "    return cur_name\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.text)\n",
        "  tags = soup('a')\n",
        "  temp = 0\n",
        "  for tag in tags :\n",
        "    temp += 1\n",
        "    if temp != pos :\n",
        "      continue\n",
        "    cur_url = tag.get('href')\n",
        "    cur_name = tag.getText()\n",
        "    return name_ret(cnt - 1, cur_url, pos, cur_name)\n",
        "\n",
        "url = input(\"Enter the url: \")\n",
        "cnt = int(input(\"Enter count: \"))\n",
        "pos = int(input(\"Enter position: \"))\n",
        "\n",
        "output = name_ret(cnt, url, pos, '')\n",
        "print(output)\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the url: http://py4e-data.dr-chuck.net/known_by_Kelsey.html\n",
            "Enter count: 7\n",
            "Enter position: 18\n",
            "Caie\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yKnj9yRxBYJ",
        "colab_type": "text"
      },
      "source": [
        "**Alternate way, not approved in coursera**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_JosvdUwsLD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "86eb56fb-d0a2-45d9-8d81-e8e8d5a58e99"
      },
      "source": [
        "import urllib.request, urllib.parse, urllib.error\n",
        "import bs4\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "def name_ret(cnt, url_name, pos, cur_name) :\n",
        "  if cnt == 0 :\n",
        "    return cur_name\n",
        "  url = urllib.request.urlopen(url_name).read()\n",
        "  soup = BeautifulSoup(url)\n",
        "  tags = soup('a')\n",
        "  temp = 0\n",
        "  for tag in tags :\n",
        "    temp += 1\n",
        "    if temp != pos :\n",
        "      continue\n",
        "    cur_url = tag.get('href')\n",
        "    cur_name = tag.getText()\n",
        "    return name_ret(cnt - 1, cur_url, pos, cur_name)\n",
        "\n",
        "url_name = input(\"Enter the url: \")\n",
        "cnt = int(input(\"Enter count: \"))\n",
        "pos = int(input(\"Enter position: \"))\n",
        "\n",
        "output = name_ret(cnt, url_name, pos, '')\n",
        "print(output)\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the url: http://py4e-data.dr-chuck.net/known_by_Kelsey.html\n",
            "Enter count: 7\n",
            "Enter position: 18\n",
            "Caie\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}